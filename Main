import pathlib
from datetime import datetime
from pathlib import Path

import numpy as np
from pylab import plot, show, grid, xlabel, ylabel
from scipy import stats
import scipy
import MathematicalModel
import NN
import Config
import Out

import torch
import torch.nn as nn
import torch.nn.functional as F
import time
import logging
import coloredlogs
import matplotlib.pyplot as plt
import matplotlib.backends.backend_pdf as pdfp
import Tests
from copy import deepcopy
import torch.optim as optim


class MainRoutine:
    def __init__(self, config, log, out):
        np.random.seed(seed=config.random_seed)

        self.out = out
        self.config = config

        self.N = config.N

        self.Model = MathematicalModel.MathematicalModel(config.T, config.d, config.mu, config.sigma, config.g, config.xi)

        self.out.Model = self.Model
        self.out.config = self.config
        self.out.T = self.Model.getT()
        self.out.N = self.N

        self.NN = NN.NN(config, self.Model, log, out)

        self.log = log

    def MainSchleife(self, test, iteration_number=0):
        log = self.log
        M = self.config.max_number_iterations  # Number of optimization steps
        T_max = self.config.max_minutes_for_iteration
        J = self.config.batch_size  # Batchsize
        L = self.config.val_size  # valsize

        train_individual_payoffs, train_average_payoff, val_continuous_value_list, val_discrete_value_list, val_path_list, train_duration, val_duration, net_net_duration, best_result = self.NN.optimization(
            M, T_max, J, L)

        final_val_cont, final_val_disc = best_result.final_validation()

        mylog("\n\nLast validation on a set of ", len(best_result.paths), " paths gave a continuous value of ", final_val_cont, " and a discrete value of ", final_val_disc, ".")

        mylog("Overall training took ", sum(train_duration), " seconds and validation took ", sum(val_duration), " seconds. ", sum(net_net_duration),
              " of the training time was spend on the net itself.")

        if self.config.other_computation_exists:
            log.info("other computation yields: %s", self.config.other_computation)

        # NN, Model, config, average_payoff, val_value_list, train_duration, val_duration, net_net_duration):
        self.out.NN = self.NN
        self.out.average_payoff = train_average_payoff
        self.out.val_continuous_value_list = val_continuous_value_list
        self.out.val_discrete_value_list = val_discrete_value_list
        self.out.train_duration = train_duration
        self.out.val_duration = val_duration
        self.out.net_net_duration = net_net_duration
        self.out.val_path_list = val_path_list
        self.out.best_result = best_result

        # TODO: Two best iterations?
        out.generate_metric_pdf(test, iteration_number)

        return iteration_number, best_result.time_to_best_result, final_val_cont, final_val_disc, self.config.get_parameter_string(), train_duration, val_duration, net_net_duration


def mylog(*argv, only_return=False):
    argv = list(argv)
    for s in range(len(argv)):
        if isinstance(argv[s], float):
            argv[s] = round(argv[s], 3)
    out = ''.join(str(s) + "\t" for s in argv)
    out += "\n"
    if not only_return:
        log.info(out)
    return out


if __name__ == '__main__':
    def resultlist_to_resultstring(list):
        """
        output_string = str(list[0]), "discrete val value: ", list[2], "cont val value:", list[1], "time spend training:", sum(list[4]), "time spend validating:", sum(
            list[5]), "time spend on net:", sum(list[6]), "Parameterstring:", list[3]
        output_string = ''.join(str(s) + "\t" for s in output_string)
        output_string += "\n"
        """
        output_string = mylog("\tThis is the ", str(list[0]), "-th run.", "discrete val value: ", list[3], "cont val value:", list[2], "time to best result:", list[1], "time spend training:",
                              sum(list[5]), "time spend validating:", sum(list[6]), "time spend on net:", sum(list[7]), "Parameterstring:", list[4], only_return=True)
        return output_string


    def sort_by_first_value(list):
        return -list[2]


    # filename='example.log'
    # stream=sys.stderr,

    log = logging.getLogger('l')
    logging.basicConfig(format='%(asctime)s:  %(message)s')
    log.setLevel(logging.DEBUG)
    # coloredlogs.install(level='DEBUG', fmt='%(asctime)s %(message)s', logger=log) # if i activate this then all the print messages are displayed

    log_name = time.strftime("%Y.%m.%d-%H.%M.%S") + ".log"

    fh = logging.FileHandler(log_name)
    formatter = logging.Formatter('%(asctime)s %(message)s')
    fh.setFormatter(formatter)
    log.addHandler(fh)

    start_time = time.time()

    test = True
    # test = False

    if test:
        folder_name = "test"
        working_directory = pathlib.Path().absolute()
        output_location = working_directory / f'{folder_name}'
        out = Out.Output(output_location)

        config_time = time.time()

        # initialisiere Configs
        config_list = []
        c1 = Config.Config("am_put1", log)
        config_list.append(c1)
        """
        c2 = deepcopy(c1)
        c2.xi = 38
        c2.compute_other_value()
        config_list.append(c2)
        """

        log.info("time for config is %s seconds" % round((time.time() - config_time), 3))
        for k in range(len(config_list)):
            log.info(str(k) + "-th config with parameters: \n" + config_list[k].get_parameter_string())
            lokaleMainRoutine = MainRoutine(config_list[k], log, out)
            lokaleMainRoutine.MainSchleife(test)

            out.create_net_pdf("net_values_" + str(k) + ".pdf")
        """
        Model = MathematicalModel.MathematicalModel(c1.T, c1.d, c1.mu, c1.sigma, c1.g, c1.xi)
        tests = Tests.Tests(out, Model)
        tests.test_good()
        """
    else:
        folder_name = "Testrun5"
        working_directory = pathlib.Path().absolute()
        output_location = working_directory / f'{folder_name}'
        out = Out.Output(output_location)

        config_list = []
        bc = Config.Config("am_put1", log)

        result_list = []
        from sklearn.model_selection import ParameterGrid

        # TODO:configs
        for params in ParameterGrid({  # 'internal_neurons'        : [5, 50, 100],
            'internal_neurons'        : [5, 50, 100],
            # TODO: alle aktivierungsfunktionen einmal mit pretrain und einmal ohne
            'internal_activation_func': [torch.tanh, torch.sigmoid, torch.nn.functional.relu, torch.nn.functional.hardtanh, torch.nn.functional.relu6,
                                         torch.nn.functional.elu, torch.nn.functional.selu, torch.nn.functional.celu, torch.nn.functional.leaky_relu,
                                         torch.nn.functional.rrelu, torch.nn.functional.gelu, torch.nn.functional.logsigmoid, torch.nn.functional.hardshrink,
                                         torch.nn.functional.tanhshrink, torch.nn.functional.softsign, torch.nn.functional.softplus, torch.nn.functional.softmin, torch.nn.functional.softmax,
                                         torch.nn.functional.softshrink, torch.nn.functional.gumbel_softmax, torch.nn.functional.log_softmax, torch.nn.functional.hardsigmoid],
            'optimizer'               : [optim.Adam],
            'initial_lernrate'        : [0.0001],
            'pretrain'                : [True],
            'pretrain_iterations'     : [300],
            'max_iterations'          : [10000],
            'max_time'                : [10],
            'batch_size'              : [16],
            'val_size'                : [64],
            'final_val'               : [256]}):
            # TODO: validation frequency
            config_list.append(deepcopy(bc))
            config_list[-1].internal_neurons = params['internal_neurons']
            config_list[-1].activation1 = params['internal_activation_func']
            config_list[-1].optimizer = params['optimizer']
            config_list[-1].initial_lr = params['initial_lernrate']
            config_list[-1].pretrain = params['pretrain']
            config_list[-1].pretrain_iterations = params['pretrain_iterations']
            config_list[-1].max_number_iterations = params['max_iterations']
            config_list[-1].max_minutes_for_iteration = params['max_time']
            config_list[-1].batch_size = params['batch_size']
            config_list[-1].val_size = params['val_size']
            config_list[-1].final_val_size = params['final_val']

        for k in range(len(config_list)):
            log.info(str(k) + "-th config with parameters: \n" + config_list[k].get_parameter_string())
            lokaleMainRoutine = MainRoutine(config_list[k], log, out)
            # k, final_val_cont, final_val_disc, parameter_string, train_duration, val_duration, net_net_duration = lokaleMainRoutine.MainSchleife(test, k)
            result_list.append(lokaleMainRoutine.MainSchleife(test, k))

            f = open("intermediate_result.txt", "w")
            # f.write("Optimization time: "+ "{0:.2f}".format(learning_max_time / 3600) +" h. Runs are sorted by val-rel error:\n")
            f.write("Optimization time: " + str(config_list[0].max_minutes_for_iteration) + " min. Other value is: " + str(config_list[0].other_computation) + ".\n")
            for j in result_list:
                f.write(resultlist_to_resultstring(j))

            f.close()

            out.create_net_pdf("net_values_" + str(k) + ".pdf")

        """
        import os

        print(os.getcwd())
        """
        result_list.sort(key=sort_by_first_value)
        # filepath = "C:/Users/Oliver/Desktop/MasterarbeitMathe/runs/Testrun1/"
        # f = open(filepath + "end_result.txt", "w")
        f = open("end_result.txt", "w")
        # f.write("Optimization time: "+ "{0:.2f}".format(learning_max_time / 3600) +" h. Runs are sorted by val-rel error:\n")
        f.write("Optimization time: 0.5 h. Runs are sorted by cont:\n")
        for k in result_list:
            f.write(resultlist_to_resultstring(k))

        f.close()

    log.info("time for everything is %s seconds" % round((time.time() - start_time), 3))
